{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c268609c",
   "metadata": {},
   "source": [
    "## Spacy Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed31019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9df832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text -- POS\n",
      " ---------\n",
      "I -- PRON\n",
      "bought -- VERB\n",
      "a -- DET\n",
      "pair -- NOUN\n",
      "of -- ADP\n",
      "watch -- NOUN\n",
      "for -- ADP\n",
      "Tom -- PROPN\n",
      "and -- CCONJ\n",
      "Elizabeth -- PROPN\n",
      "which -- PRON\n",
      "costs -- VERB\n",
      "$ -- SYM\n",
      "50 -- NUM\n",
      "each -- PRON\n",
      ". -- PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"I bought a pair of watch for Tom and Elizabeth which costs $50 each.\"\n",
    "processed = model(text)\n",
    "\n",
    "\n",
    "print(\"text -- POS\\n ---------\")\n",
    "for token in processed:\n",
    "    print(f\"{token.text} -- {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7ea923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text -- POS -- POS hash\n",
      " ---------\n",
      "I -- PRON -- 95\n",
      "bought -- VERB -- 100\n",
      "a -- DET -- 90\n",
      "pair -- NOUN -- 92\n",
      "of -- ADP -- 85\n",
      "watch -- NOUN -- 92\n",
      "for -- ADP -- 85\n",
      "Tom -- PROPN -- 96\n",
      "and -- CCONJ -- 89\n",
      "Elizabeth -- PROPN -- 96\n",
      "which -- PRON -- 95\n",
      "costs -- VERB -- 100\n",
      "$ -- SYM -- 99\n",
      "50 -- NUM -- 93\n",
      "each -- PRON -- 95\n",
      ". -- PUNCT -- 97\n"
     ]
    }
   ],
   "source": [
    "print(\"text -- POS -- POS hash\\n ---------\")\n",
    "for token in processed:\n",
    "    print(f\"{token.text} -- {token.pos_} -- {token.pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc7d147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP pipelines\n",
    "model.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f4b48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.disable_pipes('parser', 'ner')\n",
    "model.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d4480",
   "metadata": {},
   "source": [
    "## Gensim Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23cef6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary<23 unique tokens: ['Elizabeth', 'I', 'Tom', 'Tomorrow', 'a']...>\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "document = [\"Tomorrow Tom and Elizabeth are getting married, I need to buy a gift for them.\",\n",
    "            \"I bought a pair of watch for Tom and Elizabeth which costs $50 each.\"]\n",
    "\n",
    "\n",
    "# Tokenization\n",
    "tokens = [[token for token in docs.split()] for docs in document]\n",
    "\n",
    "# Create dictionary\n",
    "dictionary = Dictionary(tokens)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a077af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Elizabeth': 0,\n",
       " 'I': 1,\n",
       " 'Tom': 2,\n",
       " 'Tomorrow': 3,\n",
       " 'a': 4,\n",
       " 'and': 5,\n",
       " 'are': 6,\n",
       " 'buy': 7,\n",
       " 'for': 8,\n",
       " 'getting': 9,\n",
       " 'gift': 10,\n",
       " 'married,': 11,\n",
       " 'need': 12,\n",
       " 'them.': 13,\n",
       " 'to': 14,\n",
       " '$50': 15,\n",
       " 'bought': 16,\n",
       " 'costs': 17,\n",
       " 'each.': 18,\n",
       " 'of': 19,\n",
       " 'pair': 20,\n",
       " 'watch': 21,\n",
       " 'which': 22}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ed5be7",
   "metadata": {},
   "source": [
    "## Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c951e5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_document = \"I hope they like my gift\"\n",
    "vector = dictionary.doc2bow(new_document.lower().split())\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6d45e",
   "metadata": {},
   "source": [
    "## Model\n",
    "Let's compute the tf-idf of a document and compare it with the its vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3cbb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary : \n",
      "  {'This': 0, 'first': 1, 'is': 2, 'line': 3, 'These': 4, 'are': 5, 'lines': 6, 'second': 7, 'third': 8}\n",
      "\n",
      "\n",
      "Vector of each document: \n",
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n",
      "[(4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(0, 1), (2, 1), (3, 1), (8, 1)]\n",
      "\n",
      "\n",
      "Vector of each document in term of token:\n",
      "[['This', 1], ['first', 1], ['is', 1], ['line', 1]]\n",
      "[['These', 1], ['are', 1], ['lines', 1], ['second', 1]]\n",
      "[['This', 1], ['is', 1], ['line', 1], ['third', 1]]\n",
      "\n",
      "\n",
      "tf-idf assigned to each token:\n",
      "[['This', 0.311], ['first', 0.843], ['is', 0.311], ['line', 0.311]]\n",
      "[['These', 0.5], ['are', 0.5], ['lines', 0.5], ['second', 0.5]]\n",
      "[['This', 0.311], ['is', 0.311], ['line', 0.311], ['third', 0.843]]\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "import numpy\n",
    "\n",
    "\n",
    "documents = ['This is first line',\n",
    "            'These are second lines',\n",
    "            'This is third line']\n",
    "\n",
    "# Token\n",
    "tokens = [[token for token in docs.split()]for docs in documents]\n",
    "\n",
    "# Dictionary\n",
    "dictionary = Dictionary(tokens)\n",
    "print(\"Dictionary : \\n \", dictionary.token2id)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Vector\n",
    "print('Vector of each document: ')\n",
    "vector = [dictionary.doc2bow(token) for token in tokens]\n",
    "for vect in vector:\n",
    "    print(vect)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# BOW of each documents\n",
    "print(\"Vector of each document in term of token:\")\n",
    "for document in vector:\n",
    "    print([[dictionary[id], freq] for id, freq in document])\n",
    "\n",
    "\n",
    "\n",
    "# tfidf model\n",
    "tfidf = models.TfidfModel(vector)\n",
    "\n",
    "\n",
    "# Output of tfidf model\n",
    "print(\"\\n\")\n",
    "print(\"tf-idf assigned to each token:\")\n",
    "for document in tfidf[vector]:\n",
    "    print([[dictionary[id], numpy.around(freq, decimals=3)] for id, freq in document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e19754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
